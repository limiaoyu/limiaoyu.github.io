---
permalink: /
title: "Miaoyu Li(李杪宇)"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an autonomous driving perception algorithm engineer at RoboSense, a leading LiDAR company in China. Prior to this role, I completed my Master's degree in Computer Science at Xiamen University from September 2020 to June 2023, under the guidance of Professor Cuihua Li and Professor Yanyun Qu. 

My research interests include, but are not limited to: **Computer Vision** (3D computer vision, multi-modal fusion, point cloud semantic segmentation), **Machine Learning** (transfer learning, unsupervised learning). If you are interested in my research or have any collaboration opportunities, please feel free to contact me!

<style>
table, th, td {
  border: none;
  border-collapse: collapse;
}
</style>

_______________________________________________________________________________________________________
<h3>
  <a name="news"></a> News
</h3>
<div class="mini">
  <ul>
  <li> <strong>[Jul 2023]</strong> One paper about multi-modal domain generalized semantic segmentation is accepted by ICCV 2023!</li>
  <li> <strong>[Apr 2023]</strong> I become a reviewer for ACMMM 2023!</li>
  <li> <strong>[Mar 2023]</strong> I am the winner of Xiamen University Pan Maoyuan First-Class Scholarship!</li>
  <li> <strong>[Jul 2022]</strong> Two papers about multi-modal unsupervised domain adaptation semantic segmentation are accepted by ACMMM 2022!</li>
  </ul>
</div>

<style>
table, th, td {
  border: none;
  border-collapse: collapse;
}
</style>

_______________________________________________________________________________________________________

<h3>
  <a name="Publications"></a> Publications
</h3>

<font face="helvetica, ariel, &#39;sans serif&#39;">
        <table cellspacing="0" cellpadding="0" class="noBorder">
           <tbody>
             <tr>
                    <td width="40%">
                        <img width="320" src="../images/BEV-DG.png" border="0">
                            </td>
                    <td>
                            <b>BEV-DG: Cross-Modal Learning under Bird’s-Eye View for Domain Generalization of 3D Semantic Segmentation</b>
                    <br>
                    <strong>Miaoyu Li</strong>, Yachao Zhang, Xu Ma, Yanyun Qu, Yun Fu.
                    <br>
                    <em>IEEE/CVF International Conference on Computer Vision (ICCV 2023)</em>
                    <br>
                   [Paper</a>]
                    </td>
               </tr>
              <tr>
                    <td width="40%">
                        <img width="320" src="../images/dual-cross.jpg" border="0">
                            </td>
                    <td>
                            <b>Cross-Domain and Cross-Modal Knowledge Distillation in Domain Adaptation for 3D Semantic Segmentation</b>
                    <br>
                    <strong>Miaoyu Li</strong>*, Yachao Zhang*, Yuan Xie, Zhizhong Zhang, Cuihua Li, Yanyun Qu. 
                    <br>
                            (* indicates equal contribution)
                    <br>
                    <em>ACM International Conference on Multimedia (MM 2022)</em>
                    <br>
                   [<a href="https://dl.acm.org/doi/10.1145/3503161.3547990">Paper</a>][<a href="https://github.com/limiaoyu/Dual-Cross">Code</a>]
                    </td>
               </tr>
             <tr>
                    <td width="40%">
                        <img width="320" src="../images/SSE-xMUDA.jpg" border="0">
                            </td>
                    <td>
                    <b>SSE-xMUDA: Self-supervised Exclusive Learning for 3D Segmentation in Cross-Modal Unsupervised Domain Adaptation (Oral) </b>
                    <br>
                    Yachao Zhang, <strong>Miaoyu Li</strong>, Yuan Xie, Zhizhong Zhang, Cuihua Li, Yanyun Qu.
                    <br>
                    <em>ACM International Conference on Multimedia (MM 2022)</em>
                    <br>
                    [<a href="https://doi.org/10.1145/3503161.3547987">Paper</a>][<a href="https://github.com/limiaoyu/SSE-xMUDA">Code</a>]
                    </td>
                </tr>
                    </tbody>
           </table>
</font>

